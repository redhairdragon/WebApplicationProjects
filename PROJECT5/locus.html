<!DOCTYPE html>
<!-- saved from url=(0054)http://oak.cs.ucla.edu/classes/cs144/locust/index.html -->
<html lang="en"><!-- ***IMPORTANT***: This page is autogenerated from a markdown file
         DO NOT EDIT THIS FILE DIRECTLY.
	 Your edits will disappear when this page is regenerated  --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        code{white-space: pre-wrap;}
        span.smallcaps{font-variant: small-caps;}
        span.underline{text-decoration: underline;}
        div.line-block{white-space: pre-line;}
        div.column{display: inline-block; vertical-align: top; width: 50%;}
        pre{background-color:#e7e7e7; border: solid 1px #000000; padding: 5px;}
        code{background-color:#e7e7e7; padding: 1px;}
        div.sourceCode { overflow-x: auto; }
        table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
          margin: 0; padding: 0; vertical-align: baseline; border: none; }
        table.sourceCode { width: 100%; line-height: 100%; }
        td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
        td.sourceCode { padding-left: 5px; }
        code > span.kw { color: #0000ff; } /* Keyword */
        code > span.ch { color: #008080; } /* Char */
        code > span.st { color: #008080; } /* String */
        code > span.co { color: #008000; } /* Comment */
        code > span.ot { color: #ff4000; } /* Other */
        code > span.al { color: #ff0000; } /* Alert */
        code > span.er { color: #ff0000; font-weight: bold; } /* Error */
        code > span.wa { color: #008000; font-weight: bold; } /* Warning */
        code > span.cn { } /* Constant */
        code > span.sc { color: #008080; } /* SpecialChar */
        code > span.vs { color: #008080; } /* VerbatimString */
        code > span.ss { color: #008080; } /* SpecialString */
        code > span.im { } /* Import */
        code > span.va { } /* Variable */
        code > span.cf { color: #0000ff; } /* ControlFlow */
        code > span.op { } /* Operator */
        code > span.bu { } /* BuiltIn */
        code > span.ex { } /* Extension */
        code > span.pp { color: #ff4000; } /* Preprocessor */
        code > span.do { color: #008000; } /* Documentation */
        code > span.an { color: #008000; } /* Annotation */
        code > span.cv { color: #008000; } /* CommentVar */
        code > span.at { } /* Attribute */
        code > span.in { color: #008000; } /* Information */
    </style>
    <link rel="stylesheet" href="./locus_files/pandoc.css">
    <title></title>
</head>
<body>
<h1 id="quick-tutorial-on-locust">Quick Tutorial on Locust</h1>
<h2 id="locust-overview">Locust Overview</h2>
<p><a href="https://docs.locust.io/en/latest/what-is-locust.html">Locust</a> is an easy-to-use, distributed, user-load testing tool. It is intended for load-testing web sites (or other systems) and figuring out how many concurrent users a system can handle.</p>
<p>The idea is that during a test, a swarm of locusts will attack your website. The behavior of each locust (or test user if you will) is defined by you and the swarming process is monitored from a web UI in real-time. This will help you battle test and identify bottlenecks in your code before letting real users in.</p>
<p>In Locust, the behavior of a user is defined using a <em>task set</em> (or a set of tasks), where a task may consists of multiple requests that are issued to the server.</p>
<h2 id="simple-test-web-server">Simple Test Web Server</h2>
<p>To run Locust, we need a "web server" whose performance we want to test. In our "spark" container, we have already included a simple web server that you can use in following this tutorial. To start the web server, run the following command in the container:</p>
<pre class="term"><code>$ simple-server</code></pre>
<p>There should be a message indicating that the server started on port 3000.</p>
<p>Unfortunately, the server runs in the foreground by default, so you will need to terminate it first if you want to execute a command (like <code>ls</code>) in the container, at which point the server is no longer available.</p>
<p>There are two possible solutions for this situation:</p>
<ol type="1">
<li><p>Start another shell (either using <code>tmux</code> or by the <code>docker exec -it spark /bin/bash</code> command), and issue your next command in the new shell.</p></li>
<li><p>Start the server <em>in the background</em> through the following command:</p>
<pre class="term"><code>$ simple-server &gt; /dev/null &amp;</code></pre>
<p>The command <code>&gt; /dev/null</code> silences the output and <a href="https://www.gnu.org/software/bash/manual/html_node/Lists.html#Lists"><code>&amp;</code></a> executes the command in a child process detached from the current shell, so that you are not stuck waiting for the completion of the process. Now you should be able to issue a command.</p></li>
</ol>
<p>Using one of the above two methods, make sure that your server is running in the container and you still have an interactive shell through which you can issue commands inside the container.</p>
<h2 id="start-first-locust-performance-test">Start First Locust Performance Test</h2>
<p>Now that you have our test server running, let us run our first Locust performance test on the server. We have created a simple "locust file", <a href="http://oak.cs.ucla.edu/classes/cs144/locust/locust_file.py">locust_file.py</a>. Download the file</p>
<pre class="term"><code>$ wget http://oak.cs.ucla.edu/classes/cs144/locust/locust_file.py</code></pre>
<p>and start a Locust Web UI server based on the downloaded file:</p>
<pre class="term"><code>$ locust -f ./locust_file.py --host=http://localhost:3000</code></pre>
<p>The above command specifies the "locust file" (<code>-f</code>), which defines the "behavior of the locust (= user)" such as how many requests are issued at what intervals, etc. It also specifies the website address that we test (<code>--host</code>), which is the port <code>3000</code> at <code>http://localhost</code> in our example.</p>
<p>When you execute the above command, you are likely to see the following output, which means that Locust Web UI is now running.</p>
<pre class="term"><code>[2018-02-17 06:43:09,005] 220c94708fa6/INFO/locust.main: Starting web monitor at *:8089
[2018-02-17 06:43:09,006] 220c94708fa6/INFO/locust.main: Starting Locust 0.8.1</code></pre>
<p>Now, open a browser in your host machine and go to <a href="http://localhost:8089/" class="uri">http://localhost:8089</a>. You should be greeted with the following Locust UI asking you to "Start new Locust swarm":</p>
<figure>
<img src="./locus_files/locust-start.png" alt="Locust Start UI" width="800"><figcaption>Locust Start UI</figcaption>
</figure>
<p>Type in the number of users you want to simulate, say 200, and specify the hatch rate, say, 100. Here, the "number of user to simulate" means how many concurrent users Locust should "simulate" when it performs load testing. The "hatch rate" means the speed at which these users are created in the beginning until the specified number of concurrent users are created. (Due to the limitation of CPU performance of your machine, the actual hatch rate might be smaller than the number you specify.)</p>
<p>Now click start and see what happens. The UI will show real-time statistics on how the server responds to the requests sent by Locust:</p>
<figure>
<img src="./locus_files/locust-stat.png" alt="Locust Statistics UI" width="800"><figcaption>Locust Statistics UI</figcaption>
</figure>
<p>Here is more explanation on what the information on this page means:</p>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 86%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Term</th>
<th style="text-align: left;">Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Host</td>
<td style="text-align: left;">The address of website that we test against. (http://localhost:3000 in our case)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Status</td>
<td style="text-align: left;">The status shows "HATCHING" in the beginning when new users are spawned, but once the specified number of users have been spawned, the status changes to "RUNNING" and shows the number of concurrent users, 200 in our example.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">RPS</td>
<td style="text-align: left;">Requests per second. It shows how many HTTP requests are currently being sent to the server.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Failures</td>
<td style="text-align: left;">The percentage of requests that fails due to a connection error, timeout, page not found, bad request or similar reason. The absolute number and reason for failures are recorded in failures tab.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Stop</td>
<td style="text-align: left;">You can press this button to stop the ongoing test.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Reset Stats</td>
<td style="text-align: left;">If you click this button, all stats will be reset to zero.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Median, Average, Min, Max</td>
<td style="text-align: left;">These columns show the server response time, the interval between when the request is sent from Locust and when it receives the response from the server.</td>
</tr>
</tbody>
</table>
<p>Note that Locust will automatically reset the stats when STATUS changes from "HATCHING" to "RUNNING". The reason is the following: to get to the running state as fast as possible, usually you need to ramp up your Locusts (users) quickly. This often results in an unnaturally high stress on your server and possibly much higher response time and error rate than are typical from your server. Locust automatically resets the stats to zero once the initial ramp-up stage is over in order to prevent those ramp-up stats polluting the running stats.</p>
<p>By running Locust with different numbers of users and looking at the statistics, you can measure how well the server performs under different load conditions. Change the number of users, say to 500, and rerun the tasks to see how the performance changes. Play with the UI and get yourself familiar with the Locust UI.</p>
<h2 id="writing-locust-file">Writing Locust File</h2>
<p>Now that you are familiar with what Locust can do, let us learn how to write a locust file that describes the set of the tasks to be run for performance test. Before you proceed, take a quick look at our sample locust file, <a href="http://oak.cs.ucla.edu/classes/cs144/locust/locust_file.py">locust_file.py</a>, to get a sense of what the file looks like.</p>
<p>A locustfile is a normal python file. The only requirement is that <em>it declares at least one class</em> -- let’s call it the locust class -- that inherits from the class <code>Locust</code>.</p>
<p><strong>Note:</strong> Fortunately, you don't need to know many details of the Python language to use Locust, but in case you never used Python before, you may want to read this <a href="https://www.learnpython.org/">Python tutorial</a> to learn the basic.</p>
<h3 id="the-locust-class">The Locust class</h3>
<p>A locust class represents one user (or a swarming locust if you will). Locust will spawn (hatch) one instance of the locust class for each user that is being simulated. There are a few attributes that a locust class should typically define. For example, here is the locust class that is defined in our <code>locust_file.py</code>:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">class</span> MyLocust(HttpLocust):
    task_set <span class="op">=</span> MyTaskSet
    min_wait <span class="op">=</span> <span class="dv">1000</span>
    max_wait <span class="op">=</span> <span class="dv">2000</span></code></pre></div>
<p>Note that our locust class, <code>MyLocust</code>, inherits from <code>HttpLocust</code> (a subclass of <code>Locust</code> for generating HTTP requests). Our <code>MyLocust</code> class includes the following three attributes:</p>
<ol type="1">
<li><p><strong>task_set attribute</strong>: The <code>task_set</code> attribute should point to a <code>TaskSet</code> class which defines the behavior of the user and is described in more detail below.</p></li>
<li><p><strong>min_wait and max_wait attributes</strong>: In addition to the <code>task_set</code> attribute, one usually wants to declare the <code>min_wait</code> and <code>max_wait</code> attributes. These are the minimum and maximum time respectively, in milliseconds, that a simulated user will wait between executing each task. <code>min_wait</code> and <code>max_wait</code> default to 1000, and therefore a locust will always wait 1 second between each task if <code>min_wait</code> and <code>max_wait</code> are not declared. With our configuration, each user would wait between 1 to 2 seconds between tasks.</p></li>
</ol>
<h3 id="taskset-class">TaskSet class</h3>
<p>If the <code>Locust</code> class represents a swarming locust, you could say that the <code>TaskSet</code> class represents the brain of the locust. Each <code>Locust</code> class must have a <code>task_set</code> attribute set, that points to a <code>TaskSet</code>.</p>
<p>A <code>TaskSet</code> is, like its name suggests, a collection of tasks. These tasks are normal python functions and --- if we were load-testing an auction website --- could do stuff like "loading the start page", "searching for some product" and "making a bid".</p>
<p>When a load test is started, each instance of the spawned <code>Locust</code> classes will start executing their <code>TaskSet</code>. What happens then is that each <code>TaskSet</code> will pick one of its tasks and call it. It will then wait a number of milliseconds, chosen at random between the <code>Locust</code> class' <code>min_wait</code> and <code>max_wait</code> attributes. Then it will again pick a new task to be called, wait again, and so on.</p>
<h4 id="declaring-tasks">Declaring tasks</h4>
<p>One common way of declaring tasks for a <code>TaskSet</code> it by settings its <code>tasks</code> attribute. Here is the definition of our <code>MyTaskSet</code> that inherits from <code>TaskSet</code>:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">class</span> MyTaskSet(TaskSet):
    tasks <span class="op">=</span> {getList: <span class="dv">2</span>, previewPage: <span class="dv">1</span>}

    <span class="kw">def</span> on_start(locust):
        response <span class="op">=</span> locust.client.post(<span class="st">"/login"</span>, {<span class="st">"username"</span>:<span class="st">"cs144"</span>, <span class="st">"password"</span>: <span class="st">"password"</span>})
        <span class="cf">if</span> response.status_code <span class="op">!=</span> <span class="dv">200</span>:
            <span class="bu">print</span>(<span class="st">"FAIL to start with posting data to server. Make sure that your server is running."</span>)
            sys.exit()<span class="op">;</span></code></pre></div>
<p>The <code>tasks</code> attribute is either a list of python functions, or a python dictionary of &lt;function: integer&gt; pairs like the above example.</p>
<p>If the <code>tasks</code> attribute is set to a list of python functions like</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tasks <span class="op">=</span> [getList, previewPage]</code></pre></div>
<p>each time a task is to be performed, one function from the list will be randomly chosen and be called. When <code>tasks</code> is set to a dictionary --- with function names as keys and integer numbers as values --- the task that is to be executed will be chosen at random but with the integer value as ratio. So with our task definition:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tasks <span class="op">=</span> {getList: <span class="dv">2</span>, previewPage: <span class="dv">1</span>}</code></pre></div>
<p><code>getList</code> would be 2 times more likely to be executed than <code>previewPage</code>.</p>
<p>Note that the class <code>MyTaskSet</code> also has a method called <code>on_start</code>. The function <code>on_start</code> is called when a simulated user starts executing that <code>TaskSet</code> class. In our code, we send a POST request to the path <code>/login</code> with <code>username=cs144</code> and <code>password=password</code> and if the request fails, the task exits after printing out an error message.</p>
<p>The functions listed in the <code>tasks</code> attribute can be any python function, but they typically includes a set of commands that send HTTP requests to the server. For example, our <code>gestList</code> function</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> getList(locust):
    locust.client.get(<span class="st">'/api/cs144'</span>)
    locust.client.get(<span class="st">'/editor/post?action=list&amp;username=cs144'</span>)</code></pre></div>
<p>sends two GET requests to the server and our <code>previewPage</code> function</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> previewPage(locust):
    postid <span class="op">=</span> random.randint(<span class="dv">1</span>, <span class="dv">100</span>)
    url_prefix <span class="op">=</span> <span class="st">'/blog/cs144/'</span><span class="op">;</span>
    locust.client.get(url_prefix <span class="op">+</span> <span class="bu">str</span>(postid), name<span class="op">=</span>url_prefix)</code></pre></div>
<p>sends one GET request to the server with a <em>random postid</em>. Note that we specify the <code>url_prefix</code> as the value for parameter <code>name</code> of the <code>get</code> method, because Locust will by default use the URL as the <code>name</code> for grouping stats. Every post with a different postid will be considered as one separate row in the stats table if we don't specify the <code>name</code>. You may want to delete <code>name=url_prefix</code> and see what happens in Locust statistics dashboard.</p>
<h2 id="run-locust-without-web-ui">Run Locust without Web UI</h2>
<p>As the last topic of this Locust tutorial, let us learn how to run Locust without the web UI and save its results into a file:</p>
<pre class="term"><code>$ locust -f ./locust_file.py --host=http://localhost:3000 --no-web -c 100 -r 100 -n 2000</code></pre>
<p>The <code>--no-web</code> in command indicates that we would disable the web UI and run it immediately within console. <code>-c</code> specifies the number of users, <code>-r</code> specifies the hatch rate and <code>-n</code> specifies the total number of requests before Locust exit (otherwise the process will run forever!)</p>
<p>When executing the above command, Locust will start the test and print out the stats in every 2 seconds until it reaches the total number of requests we specified, at which point the process will exit and print the summary. In general, you are likely to see an output similar to the following:</p>
<pre class="term"><code>[2018-02-18 19:26:58,521] 220c94708fa6/INFO/locust.main: Starting Locust 0.8.1
[2018-02-18 19:26:58,521] 220c94708fa6/INFO/locust.runners: Hatching and swarming 100 clients at the rate 100 clients/s
...
Name                                      # reqs    # fails  Avg  Min   Max  | Median   req/s
----------------------------------------------------------------------------------------------
...
[2018-02-18 19:36:24,618] 220c94708fa6/INFO/locust.runners: All locusts hatched: WebsiteUser: 100
[2018-02-18 22:36:24,619] 220c94708fa6/INFO/locust.runners: Resetting stats
Name                                      # reqs    # fails  Avg  Min   Max  | Median   req/s
----------------------------------------------------------------------------------------------
...
[2018-02-18 19:53:28,140] 220c94708fa6/INFO/locust.runners: All locusts dead
[2018-02-18 19:53:28,140] 220c94708fa6/INFO/locust.main: Shutting down (exit code 0), bye.
Name                                      # reqs    # fails  Avg  Min   Max  | Median   req/s
----------------------------------------------------------------------------------------------
GET /api/cs144                               866   0(0.00%)   15    2   159  |      5   65.70
GET /blog/cs144/                             425   0(0.00%)   13    2   154  |      5   31.50
GET /editor/post?action=list&amp;username=cs144  808   0(0.00%)   13    2   160  |      5   65.70
POST /login                                    0   0(0.00%)    0    0     0  |      0    0.00
----------------------------------------------------------------------------------------------
Total                                       2099   0(0.00%)                            162.90

Percentage of the requests completed within given times
Name                                      # reqs   50%  66%  75%  80%  90%  95%  98%  99% 100%
----------------------------------------------------------------------------------------------
GET /api/cs144                               866     5    9   14   20   43   59  120  130  159
GET /blog/cs144/                             425     5    8   12   16   32   53  110  130  154
GET /editor/post?action=list&amp;username=cs144  808     5    8   14   19   34   49   73   88  160
----------------------------------------------------------------------------------------------</code></pre>
<p>Let's take a look at the last table, which describes the distribution of the response time. In the first row of table, we have 866 requests sent to <code>/api/cs144</code> using the <code>GET</code> method that received responses, among which 50% of requests are responded in 5ms, 90% are responded in 43ms, and 99% are within 130ms. Let's say if the response time is required to be less than 120ms, our website handles 98% of the users within this limit while 100 users are visiting the website every second.</p>
<p>You might notice that the number of requests for <code>GET /api/cs144</code> is different from that of <code>GET /editor/post?action=list&amp;username=cs144</code>. The reason is that Locust only counts the requests that have been responded, otherwise those requests wouldn't have stats of response time. When Locust finds the total number of requests has already exceeded what we specified (i.e. 2000), it will simply stop counting, print the summary and exit even though some of the requests it sent haven't been responded. And the reason why <code>POST /login</code> doesn't have any request is because all of the users and their post requests will be generated during "HATCHING" and Locust automatically resets the stats when it changes from "HATCHING" to "RUNNING". If you append the option <code>--no-reset-stats</code> to the command, you will be able to see exactly 100 requests from <code>POST /login</code>.</p>
<p><strong>Note</strong>: Sometimes, the total number of requests may be reached before Locust finishes hatching all users, in which case you may encounter <a href="https://github.com/locustio/locust/issues/512">a bug in Locust</a>; when this bug is triggered, Locust does not stop after the limit is reached, but instead starts again from the beginning (with fewer clients)! If you encounter this bug, therefore, just increase the limit of total requests to the point that all users will be hatched before reaching the number.</p>
<p>Sometimes we don't really need all the details when running the test, and the summary table printed at the end is sufficient to tell the whole story. We can run Locust without the web UI and save <em>only the summary</em> to the file <code>summary.txt</code> by the following command:</p>
<pre class="term"><code>$ locust -f ./locust_file.py --host=http://localhost:3000 --no-web -c 100 -r 100 -n 2000 --only-summary |&amp; tee summary.txt</code></pre>
<p>The <code>--only-summary</code> option tells Locust to suppress the stats output during the test and only print the summary. <code>|&amp;</code> is a UNIX pipe to redirect STDERR and STDOUT of the Locust process to STDIN of the UNIX command <code>tee</code>. And the UNIX command <code>tee</code> would print all message to the console as well as saving the message in the file specfied as its parameter.</p>
<p>Note that due to the bug we mentioned, your might want to try the command first without adding <code>--only-summary</code> incase the bug is triggered and the tests do not finish. If it happens, increase the total request limit to whatever number that works.</p>
<p>Now you have learned enough about Locust to finish this project. But if you want to learn more, check out the <a href="https://docs.locust.io/en/latest/writing-a-locustfile.html">Locust documentation</a>.</p>
<p>Before leaving this tutorial, you might want to stop our simple server by the following command if you ran it in the background:</p>
<pre class="term"><code>$ pkill simple-server &amp;&amp; pkill node</code></pre> 


</body></html>